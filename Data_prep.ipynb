{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3019c8ae",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b607d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any Pip installs we need for this project\n",
    "!pip install sklearn\n",
    "!pip install pandas\n",
    "!pip install earthpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6738177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries we need for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import earthpy as et\n",
    "import math\n",
    "import statistics\n",
    "from statistics import stdev\n",
    "import requests\n",
    "import os.path \n",
    "import csv \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3021d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data prep functions\n",
    "\n",
    "def get_arrest_data():\n",
    "    # I just picked the biggest dataset - this will take a few minutes to download. luckly you will only need to \n",
    "    # download this once\n",
    "    file_url = \"https://stacks.stanford.edu/file/druid:yg821jf8611/yg821jf8611_ca_statewide_2020_04_01.csv.zip\"\n",
    "    data_file = et.data.get_data(url=file_url)\n",
    "    fname = os.path.join(data_file, \"ca_statewide_2020_04_01.csv\")\n",
    "    return pd.read_csv(fname, on_bad_lines='skip')\n",
    "\n",
    "def shuffle_data(data, seed):\n",
    "    np.random.seed(seed)\n",
    "    try:\n",
    "        np.random.shuffle(data.values)\n",
    "    except:\n",
    "        np.random.shuffle(data)\n",
    "    return(data)\n",
    "\n",
    "# splits data into training(2/3) and validation(1/3) dataframes\n",
    "def split_data(data_frame):\n",
    "    training_length = round(2/3 * len(data_frame))\n",
    "\n",
    "    training_df = data_frame[:training_length]\n",
    "    validation_df = data_frame[training_length:]\n",
    "\n",
    "    return training_df, validation_df\n",
    "\n",
    "# assuming that that yhat column is the last column in the dataset, this returns the features seperated from\n",
    "# the yhat column. for example to use this function: 'arrest_feat_df, arrest_yhat_df = split_data_yhat(df)'\n",
    "def split_data_yhat(df):\n",
    "    # This function will not work on our dataset - our yhat is 'arrest_made' column and it is not the \n",
    "    # last column of the dataset. so if someone needs this - you will have to re-write this function.\n",
    "    return df.iloc[:,:-1], df.iloc[:,-1]\n",
    "def moveYcolumnToEnd(data, indexOfY):\n",
    "    #takes a numpy array and moves column at \"indexOfY\" to the last column of the array.  \n",
    "    #All columns at indexes greater than \"indexOfY\" are shifted to the left by one.\n",
    "    numOfRow, NumOfColumns = data.shape\n",
    "    if(indexOfY < NumOfColumns):\n",
    "        data[:, indexOfY:] = np.roll(data[:, indexOfY:], -1, 1)\n",
    "    else:\n",
    "        print(\"Your Y index is out of range, cannot move column\")\n",
    "    return data\n",
    "\n",
    "def get_arrest_data2():\n",
    "    #gets the data from a local file if it exists\n",
    "    if os.path.exists('tn_nashville_2020_04_01.csv'):\n",
    "        print(\"File already exists, getting data locally.....\")\n",
    "        data = pd.read_csv('tn_nashville_2020_04_01.csv',on_bad_lines='skip', dtype=str)\n",
    "        return data\n",
    "    else:\n",
    "        file_url = 'https://stacks.stanford.edu/file/druid:yg821jf8611/yg821jf8611_tn_nashville_2020_04_01.csv.zip'\n",
    "        data_file = et.data.get_data(url=file_url)\n",
    "        fname = os.path.join(data_file, 'tn_nashville_2020_04_01.csv')\n",
    "        return pd.read_csv(fname, on_bad_lines='skip', dtype=str)\n",
    "\n",
    "def encodeFeatures(dataframe,skipColumnsList=[]):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for column in dataframe.columns:\n",
    "        if column not in skipColumnsList:\n",
    "            # Converting string labels into numbers.\n",
    "            dataframe[column]=le.fit_transform(dataframe[column])\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def replaceNulls(data):\n",
    "#takes in a numpy array and replaces missing null values with the most frequent values in that column\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    imp.fit(data)\n",
    "    SimpleImputer()\n",
    "    return imp.transform(data)\n",
    "\n",
    "def truncateTime(time):\n",
    "    #truncates time values to just the hour   \n",
    "    return str(time)[0:2]\n",
    "\n",
    "def convertAgeFeature(stringAge):\n",
    "    young =0\n",
    "    middle = 1\n",
    "    old =2\n",
    "    convertedAge = 0\n",
    "    age = float(stringAge)\n",
    "    if  age >= 25:\n",
    "        if age < 50:\n",
    "            convertedAge = 1\n",
    "        else:\n",
    "            convertedAge = 2\n",
    "   \n",
    "    return convertedAge\n",
    "\n",
    "def getPreprocessedArrestData():\n",
    "    arrest_dataFrame = get_arrest_data2().copy()\n",
    "    arrest_dataFrame = arrest_dataFrame.dropna()\n",
    "    arrest_data = arrest_dataFrame[['subject_race', 'subject_sex','subject_age','time','violation','frisk_performed','search_vehicle','warning_issued']].copy()\n",
    "    #print(arrest_data.head(10))\n",
    "    #arrest_data = truncateTime(data)\n",
    "    arrest_data['time'] = arrest_data['time'].apply(lambda x : truncateTime(x))\n",
    "    arrest_data['subject_age'] = arrest_data['subject_age'].apply(lambda x : convertAgeFeature(x))\n",
    "    #skipColumnsList=['time','subject_age']\n",
    "    arrest_data = encodeFeatures(arrest_data)   \n",
    "    #data = data.to_numpy()\n",
    "    #arrest_data=replaceNulls(data)\n",
    "    return arrest_data\n",
    "\n",
    "def getPreprocessedArrestDataWithoutRace():\n",
    "    arrest_dataFrame = get_arrest_data2().copy()\n",
    "    arrest_dataFrame = arrest_dataFrame.dropna()\n",
    "    arrest_data = arrest_dataFrame[['subject_sex','subject_age','time','violation','frisk_performed','search_vehicle','warning_issued']].copy()\n",
    "    #arrest_data = truncateTime(data)\n",
    "    arrest_data['time'] = arrest_data['time'].apply(lambda x : truncateTime(x))\n",
    "    arrest_data['subject_age'] = arrest_data['subject_age'].apply(lambda x : convertAgeFeature(x))\n",
    "    #skipColumnsList=['time','subject_age']\n",
    "    arrest_data = encodeFeatures(arrest_data)    \n",
    "    #data = data.to_numpy()\n",
    "    #arrest_data=replaceNulls(data)\n",
    "    return arrest_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff3ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this for testing\n",
    "arrest_data_df = Data_prep.get_arrest_data()\n",
    "print(arrest_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d27eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
